{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport os\nimport cv2\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\n\n# style your matplotlib\nmpl.style.use(\"seaborn-darkgrid\")\n# run this block","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"files=os.listdir(\"../input/face-recognition-30/dataset/\")\nfiles","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_array=[]  # it's a list later i will convert it to array\nlabel_array=[]\npath=\"../input/face-recognition-30/dataset/\"\n# loop through each sub-folder in train\nfor i in range(len(files)):\n    # files in sub-folder\n    file_sub=os.listdir(path+files[i])\n\n    for k in tqdm(range(len(file_sub))):\n        try:\n            img=cv2.imread(path+files[i]+\"/\"+file_sub[k])\n            img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n            img=cv2.resize(img,(96,96))\n            image_array.append(img)\n            label_array.append(i)\n        except:\n            pass","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimage_array=np.array(image_array)/255.0\nlabel_array=np.array(label_array)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train,X_test,Y_train,Y_test=train_test_split(image_array,label_array,test_size=0.15)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras import layers,callbacks,utils,applications,optimizers\nfrom keras.models import Sequential,Model,load_model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(files)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=Sequential()\n# I will use MobileNetV2 as an pretrained model \npretrained_model=tf.keras.applications.EfficientNetB0(input_shape=(96,96,3),include_top=False,\n                                         weights=\"imagenet\")\nmodel.add(pretrained_model)\nmodel.add(layers.GlobalAveragePooling2D())\n# add dropout to increase accuracy by not overfitting\nmodel.add(layers.Dropout(0.3))\n# add dense layer as final output\nmodel.add(layers.Dense(1))\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer=\"adam\",loss=\"mean_squared_error\",metrics=[\"mae\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# creating a chechpoint to save model at best accuarcy\n\nckp_path=\"trained_model/model\"\nmodel_checkpoint=tf.keras.callbacks.ModelCheckpoint(filepath=ckp_path,\n                                                   monitor=\"val_mae\",\n                                                   mode=\"auto\",\n                                                   save_best_only=True,\n                                                   save_weights_only=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create a lr reducer which decrease learning rate when accuarcy does not increase\nreduce_lr=tf.keras.callbacks.ReduceLROnPlateau(factor=0.9,monitor=\"val_mae\",\n                                             mode=\"auto\",cooldown=0,\n                                             patience=5,verbose=1,min_lr=1e-6)\n# patience : wait till 5 epoch\n# verbose : show accuracy every 1 epoch\n# min_lr=minimum learning rate\n#","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCHS=300\nBATCH_SIZE=64\n\nhistory=model.fit(X_train,\n                 Y_train,\n                 validation_data=(X_test,Y_test),\n                 batch_size=BATCH_SIZE,\n                 epochs=EPOCHS,\n                 callbacks=[model_checkpoint,reduce_lr]\n                 )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_weights(ckp_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"converter = tf.lite.TFLiteConverter.from_keras_model(model)\ntflite_model = converter.convert()\n\n# Save the model.\nwith open('model.tflite', 'wb') as f:\n  f.write(tflite_model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction_val=model.predict(X_test,batch_size=BATCH_SIZE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction_val[:20]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_test[:20]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}